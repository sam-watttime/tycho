{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import folium\n",
    "import geehydro\n",
    "\n",
    "import sqlite3\n",
    "import os\n",
    "import ftplib\n",
    "import concurrent.futures as cf\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "import config\n",
    "import helper\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....connecting to sqlite for 860/923 data\n",
      "....loading plant level data\n",
      "....loading generator eightsixty data\n",
      "........filtering to report years: len 27991\n",
      "........filtering out retirements in next year: len 27662\n",
      "........filtering out non-operational assets: len 21789\n",
      "........filtering out non-fossil generators: len 12008\n",
      "........reducing generators to plant level: len 3327\n",
      "....merging dbs\n",
      "........merging eightsixty with plants on plant_id_eia: len 3327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plant_id_eia</th>\n",
       "      <th>report_year</th>\n",
       "      <th>capacity_mw</th>\n",
       "      <th>summer_capacity_mw</th>\n",
       "      <th>winter_capacity_mw</th>\n",
       "      <th>minimum_load_mw</th>\n",
       "      <th>fuel_type_code_pudl</th>\n",
       "      <th>multiple_fuels</th>\n",
       "      <th>planned_retirement_year</th>\n",
       "      <th>plant_name_eia</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "      <th>timezone</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>2569.500000</td>\n",
       "      <td>2337.899902</td>\n",
       "      <td>2370.100098</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Barry</td>\n",
       "      <td>Bucks</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>31.007000</td>\n",
       "      <td>-88.010002</td>\n",
       "      <td>AL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-88.01000 31.00700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Gadsden</td>\n",
       "      <td>Gadsden</td>\n",
       "      <td>Etowah</td>\n",
       "      <td>34.013000</td>\n",
       "      <td>-85.971001</td>\n",
       "      <td>AL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-85.97100 34.01300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>86.900002</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Copper</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>31.757000</td>\n",
       "      <td>-106.375000</td>\n",
       "      <td>TX</td>\n",
       "      <td>America/Denver</td>\n",
       "      <td>POINT (-106.37500 31.75700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>1288.400024</td>\n",
       "      <td>1256.099976</td>\n",
       "      <td>1400.099976</td>\n",
       "      <td>814.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>1</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>Demopolis</td>\n",
       "      <td>Greene</td>\n",
       "      <td>32.602001</td>\n",
       "      <td>-87.780998</td>\n",
       "      <td>AL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-87.78100 32.60200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2018</td>\n",
       "      <td>2034.000000</td>\n",
       "      <td>1868.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>996.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>1</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>E C Gaston</td>\n",
       "      <td>Wilsonville</td>\n",
       "      <td>Shelby</td>\n",
       "      <td>33.243999</td>\n",
       "      <td>-86.458000</td>\n",
       "      <td>AL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-86.45800 33.24400)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>62757</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Bridgewater Complex Co-Generation Plant</td>\n",
       "      <td>Bridgewater</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>41.931999</td>\n",
       "      <td>-70.958000</td>\n",
       "      <td>MA</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-70.95800 41.93200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>62762</td>\n",
       "      <td>2018</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>NASA Johnson Space Center CHP</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>29.562000</td>\n",
       "      <td>-95.088997</td>\n",
       "      <td>TX</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-95.08900 29.56200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>62859</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Coventry Clean Energy Corporation</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Orleans</td>\n",
       "      <td>44.909000</td>\n",
       "      <td>-72.221001</td>\n",
       "      <td>VT</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-72.22100 44.90900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>62901</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Phoenix Contact - CCHP Plant</td>\n",
       "      <td>Middletown</td>\n",
       "      <td>Dauphin</td>\n",
       "      <td>40.229000</td>\n",
       "      <td>-76.750000</td>\n",
       "      <td>PA</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-76.75000 40.22900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>62920</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.3</td>\n",
       "      <td>gas</td>\n",
       "      <td>0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Burrstone Energy Center</td>\n",
       "      <td>New Hartford</td>\n",
       "      <td>Oneida</td>\n",
       "      <td>43.095001</td>\n",
       "      <td>-75.278000</td>\n",
       "      <td>NY</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-75.27800 43.09500)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3327 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      plant_id_eia  report_year  capacity_mw  summer_capacity_mw  \\\n",
       "0                3         2018  2569.500000         2337.899902   \n",
       "1                7         2018   138.000000          130.000000   \n",
       "2                9         2018    86.900002           64.000000   \n",
       "3               10         2018  1288.400024         1256.099976   \n",
       "4               26         2018  2034.000000         1868.000000   \n",
       "...            ...          ...          ...                 ...   \n",
       "3322         62757         2018     1.500000            1.500000   \n",
       "3323         62762         2018    11.200000           10.600000   \n",
       "3324         62859         2018     8.000000            7.500000   \n",
       "3325         62901         2018     1.000000            1.000000   \n",
       "3326         62920         2018     3.600000            3.600000   \n",
       "\n",
       "      winter_capacity_mw  minimum_load_mw fuel_type_code_pudl  multiple_fuels  \\\n",
       "0            2370.100098           1421.0                 gas               0   \n",
       "1             130.000000             56.0                 gas               0   \n",
       "2              64.000000              3.0                 gas               0   \n",
       "3            1400.099976            814.0                 gas               1   \n",
       "4            1872.000000            996.0                 gas               1   \n",
       "...                  ...              ...                 ...             ...   \n",
       "3322            1.500000              0.5                 gas               0   \n",
       "3323           11.400000              4.6                 gas               0   \n",
       "3324            7.500000              7.5                 gas               0   \n",
       "3325            1.000000              0.1                 gas               0   \n",
       "3326            3.600000              2.3                 gas               0   \n",
       "\n",
       "      planned_retirement_year                           plant_name_eia  \\\n",
       "0                      2099.0                                    Barry   \n",
       "1                      2099.0                                  Gadsden   \n",
       "2                      2099.0                                   Copper   \n",
       "3                      2099.0                            Greene County   \n",
       "4                      2099.0                               E C Gaston   \n",
       "...                       ...                                      ...   \n",
       "3322                   2099.0  Bridgewater Complex Co-Generation Plant   \n",
       "3323                   2099.0            NASA Johnson Space Center CHP   \n",
       "3324                   2099.0        Coventry Clean Energy Corporation   \n",
       "3325                   2099.0             Phoenix Contact - CCHP Plant   \n",
       "3326                   2099.0                  Burrstone Energy Center   \n",
       "\n",
       "              city   county   latitude   longitude state          timezone  \\\n",
       "0            Bucks   Mobile  31.007000  -88.010002    AL   America/Chicago   \n",
       "1          Gadsden   Etowah  34.013000  -85.971001    AL   America/Chicago   \n",
       "2          El Paso  El Paso  31.757000 -106.375000    TX    America/Denver   \n",
       "3        Demopolis   Greene  32.602001  -87.780998    AL   America/Chicago   \n",
       "4      Wilsonville   Shelby  33.243999  -86.458000    AL   America/Chicago   \n",
       "...            ...      ...        ...         ...   ...               ...   \n",
       "3322   Bridgewater  Bristol  41.931999  -70.958000    MA  America/New_York   \n",
       "3323       Houston   Harris  29.562000  -95.088997    TX   America/Chicago   \n",
       "3324      Coventry  Orleans  44.909000  -72.221001    VT  America/New_York   \n",
       "3325    Middletown  Dauphin  40.229000  -76.750000    PA  America/New_York   \n",
       "3326  New Hartford   Oneida  43.095001  -75.278000    NY  America/New_York   \n",
       "\n",
       "                         geometry  \n",
       "0      POINT (-88.01000 31.00700)  \n",
       "1      POINT (-85.97100 34.01300)  \n",
       "2     POINT (-106.37500 31.75700)  \n",
       "3      POINT (-87.78100 32.60200)  \n",
       "4      POINT (-86.45800 33.24400)  \n",
       "...                           ...  \n",
       "3322   POINT (-70.95800 41.93200)  \n",
       "3323   POINT (-95.08900 29.56200)  \n",
       "3324   POINT (-72.22100 44.90900)  \n",
       "3325   POINT (-76.75000 40.22900)  \n",
       "3326   POINT (-75.27800 43.09500)  \n",
       "\n",
       "[3327 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~ LOAD PUDL 860/923 ~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "class PUDLLoader():\n",
    "    def __init__(self, years=2018,\n",
    "                 round_coords_at=3,\n",
    "                 ts_frequency='D'):\n",
    "        \n",
    "        assert ts_frequency in ['D','H']\n",
    "        \n",
    "        self.years = years\n",
    "        self.round_coords_at = round_coords_at\n",
    "        self.ts_frequency = ts_frequency\n",
    "        \n",
    "    def _connect_to_sqlite(self):\n",
    "        print('....connecting to sqlite for 860/923 data')\n",
    "        self.db_path = os.path.join('data','pudl-work','sqlite','pudl.sqlite')\n",
    "        self.engine = sqlite3.connect(self.db_path)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _load_plants_entity_eia(self):\n",
    "        print('....loading plant level data')\n",
    "        self.plants = pd.read_sql_query(\"SELECT * FROM plants_entity_eia\", self.engine)\n",
    "        self.plants = helper.memory_downcaster(self.plants)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _load_generators_eia860(self):\n",
    "        print('....loading generator eightsixty data')\n",
    "        self.eightsixty = pd.read_sql_query(\"SELECT * FROM generators_eia860\", self.engine)\n",
    "        self.eightsixty = helper.memory_downcaster(self.eightsixty)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _clean_eightsixty(self):\n",
    "        keep = [\n",
    "            'plant_id_eia',\n",
    "            'report_year',\n",
    "            'operational_status',\n",
    "            'capacity_mw',\n",
    "            'summer_capacity_mw',\n",
    "            'winter_capacity_mw',\n",
    "            'fuel_type_code_pudl',\n",
    "            'multiple_fuels',\n",
    "            'planned_retirement_year',\n",
    "            'minimum_load_mw',\n",
    "        ]\n",
    "\n",
    "        agg_dict = {\n",
    "            'capacity_mw':'sum',\n",
    "            'summer_capacity_mw':'sum',\n",
    "            'winter_capacity_mw':'sum',\n",
    "            'minimum_load_mw':'sum',\n",
    "            'fuel_type_code_pudl':'first',\n",
    "            'multiple_fuels':'max',\n",
    "            'planned_retirement_year':'max',\n",
    "        }\n",
    "\n",
    "        # --- convert to datetime ---\n",
    "        self.eightsixty['report_date'] = pd.to_datetime(self.eightsixty['report_date'])\n",
    "        self.eightsixty['planned_retirement_date'] = pd.to_datetime(self.eightsixty['planned_retirement_date'])\n",
    "        self.eightsixty['report_year'] = [i.year for i in self.eightsixty['report_date']]\n",
    "        self.eightsixty['planned_retirement_year'] = [i.year for i in self.eightsixty['planned_retirement_date']]\n",
    "\n",
    "        # --- only take input year ---\n",
    "        self.eightsixty = self.eightsixty.loc[self.eightsixty['report_year'].isin(self.years)]\n",
    "        print(f'........filtering to report years: len {len(self.eightsixty)}')\n",
    "\n",
    "        # --- take out possible retirements within next two years ---\n",
    "        self.eightsixty['planned_retirement_year'].fillna(2099, inplace=True) #fill in nans for plants with no planned retirement\n",
    "        self.eightsixty = self.eightsixty.loc[self.eightsixty['planned_retirement_year'] > self.eightsixty['report_year'] + 2]\n",
    "        print(f'........filtering out retirements in next year: len {len(self.eightsixty)}')\n",
    "\n",
    "        # --- only take operational assets ---\n",
    "        self.eightsixty = self.eightsixty.loc[self.eightsixty['operational_status'] == 'existing']\n",
    "        print(f'........filtering out non-operational assets: len {len(self.eightsixty)}')\n",
    "\n",
    "        # --- only take fossil generators ---\n",
    "        self.eightsixty = self.eightsixty.loc[self.eightsixty['fuel_type_code_pudl'].isin(['coal','gas','oil'])]\n",
    "        print(f'........filtering out non-fossil generators: len {len(self.eightsixty)}')\n",
    "                \n",
    "        # --- filter out columns ---\n",
    "        self.eightsixty = self.eightsixty[keep]\n",
    "        \n",
    "        # --- groupby to reduce multiple generators at one plant ---\n",
    "        self.eightsixty = self.eightsixty.groupby(['plant_id_eia','report_year'], as_index=False).agg(agg_dict)\n",
    "        print(f'........reducing generators to plant level: len {len(self.eightsixty)}')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _clean_plants(self):\n",
    "        \n",
    "        keep = [\n",
    "            'plant_id_eia',\n",
    "            'plant_name_eia',\n",
    "            'city',\n",
    "            'county', \n",
    "            'latitude',\n",
    "            'longitude',\n",
    "            'state',\n",
    "            'timezone'\n",
    "        ]\n",
    "        \n",
    "        # --- Round coordinates ---\n",
    "        self.plants[['latitude','longitude']] = self.plants[['latitude','longitude']].round(self.round_coords_at)\n",
    "        \n",
    "        # --- Filter out unnecessary columns ---\n",
    "        self.plants = self.plants[keep]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _make_geopandas(self):\n",
    "        self.eightsixty = gpd.GeoDataFrame(\n",
    "            self.eightsixty, geometry=gpd.points_from_xy(self.eightsixty['longitude'], self.eightsixty['latitude']))\n",
    "        self.eightsixty.crs = \"EPSG:4326\"\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def _merge_dbs(self):\n",
    "        print('....merging dbs')\n",
    "        \n",
    "        # --- Merge plant data with generator data ---\n",
    "        self.eightsixty = self.eightsixty.merge(self.plants, on='plant_id_eia', how='inner')\n",
    "        print(f'........merging eightsixty with plants on plant_id_eia: len {len(self.eightsixty)}')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def load(self):\n",
    "        \n",
    "        # --- Grab SQLite data ---\n",
    "        self._connect_to_sqlite()\n",
    "        self._load_plants_entity_eia()\n",
    "        self._load_generators_eia860()\n",
    "        \n",
    "        # --- Clean ---\n",
    "        self._clean_eightsixty()\n",
    "        self._clean_plants()\n",
    "        \n",
    "        # --- Merge ---\n",
    "        self._merge_dbs() #merge eightsixty and plants\n",
    "        \n",
    "        # --- Make Geopandas ---\n",
    "        self._make_geopandas()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "pudlloader = PUDLLoader()\n",
    "pudlloader.load()\n",
    "\n",
    "eightsixty = pudlloader.eightsixty\n",
    "eightsixty = eightsixty[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~ LOAD EPA CEMS DATA ~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\"\"\"\n",
    "The EPA requires certain thremal generators within the U.S. to report\n",
    "certain emission outputs on an hourly basis, including NOx, SO2, and CO2.\n",
    "\n",
    "Many of these values are measured, however some are calculated or imputed based\n",
    "on known emission outputs and MWh of production (also reported on an hourly basis).\n",
    "\n",
    "This data will serve as the training target (y_train values) for our supervised learning model.\n",
    "\n",
    "We will build an ML pipeline that trains on this data, and can predict for the rest\n",
    "of the world (where we don't have EPA CEMS data). \n",
    "\n",
    "This module contains two classes:\n",
    "    1) EPACEMSScraper scrapes .csvs from an FTP server hosted by the EIA.\n",
    "       csvs are segmented by state and month. This script will download any\n",
    "       files that are not present, and skip files that are already downloaded. \n",
    "       \n",
    "       If the EPA ever updates files (which they often do around the September/October)\n",
    "       timeframe for the previous year, it is responsible to delete the files locally\n",
    "       and rerun the scraper to download new files. \n",
    "       \n",
    "    2) CEMSLoader loads the csvs and performs sanitizing functions.\n",
    "       This includes:\n",
    "           - aggregating multiple units into a single plant\n",
    "           - resampling hourly data to the desired resoultion ('D' for daily by default)\n",
    "           - dropping plants without a full year of data\n",
    "           - dropping plants with a significant amount of missing or nan values\n",
    "           - dropping plants without any reported emissions\n",
    "           - converting emission units from tons to lbs\n",
    "           - cleaning up column names\n",
    "           - reducing memory consumption by converting dtypes where possible\n",
    "    \n",
    "        This script can be time consuming, and if sub-daily resolution is used can result in very large\n",
    "        file sizes. However if daily resoultion is used, the resulting files is only ~ 12 MB pickled,\n",
    "        and saved to a 'data/CEMS/processed' file. If an identical query (year/ts_frequency) is performed,\n",
    "        the processed pickle will be loaded to save time. \n",
    "\"\"\"\n",
    "\n",
    "class EPACEMSScraper():\n",
    "    def __init__(self, server='newftp.epa.gov',\n",
    "                 server_dir='DMDnLoad/emissions/hourly/monthly/',\n",
    "                 download_path=os.path.join('data','CEMS','csvs'),\n",
    "                 years=[2019]):\n",
    "        \n",
    "        self.server=server\n",
    "        self.server_dir = server_dir\n",
    "        self.download_path = download_path\n",
    "        self.years=years\n",
    "    \n",
    "    def _connect_to_ftp(self):\n",
    "        self.ftp = ftplib.FTP(self.server)\n",
    "        self.ftp.login()\n",
    "        print('....connected to EPA CEMS FTP Server')\n",
    "        return self\n",
    "    \n",
    "    def _cwd_annual(self, year):\n",
    "        year_server_dir = self.server_dir + str(year) + '/'\n",
    "        self.ftp.cwd(year_server_dir)\n",
    "        files = self.ftp.nlst()\n",
    "        print('........downloaded file list from EPA CEMS FTP Server')\n",
    "        return files\n",
    "    \n",
    "    def _already_downloaded(self, files):\n",
    "        \"\"\"Check what is already downloaded and skip it.\"\"\"\n",
    "        downloaded = os.listdir(self.download_path)\n",
    "        needed = [f for f in files if f not in downloaded]\n",
    "        print(f'....{len(needed)} files needed, {len(downloaded) - len(needed)} files already downloaded')\n",
    "        return needed\n",
    "        \n",
    "    \n",
    "    def _worker(self, f):\n",
    "        self.ftp.retrbinary(\"RETR \" + f, open(os.path.join(self.download_path, f), \"wb\").write)\n",
    "        time.sleep(0.5)\n",
    "        return\n",
    "    \n",
    "    def fetch(self):\n",
    "        \n",
    "        # --- Connect to FTP ---\n",
    "        self._connect_to_ftp()\n",
    "        \n",
    "        # --- Loop through years ---\n",
    "        for y in self.years:\n",
    "            print(f'....working on {y}')\n",
    "            jobs = self._cwd_annual(y)\n",
    "            jobs = self._already_downloaded(jobs)\n",
    "        \n",
    "            # --- Download monthly/state files ---\n",
    "            jobs_complete = 0 \n",
    "            to_do = len(jobs)\n",
    "            ten_percent = int(to_do*0.1)\n",
    "            \n",
    "            for job in jobs: #FTP limits connections, so multiprocessing doesn't work\n",
    "                self._worker(job)\n",
    "                jobs_complete += 1\n",
    "                    \n",
    "                if jobs_complete % ten_percent == 0:\n",
    "                    print('........finished EPA CEMS download {} / {}'.format(jobs_complete, to_do))\n",
    "        print(f'....finished all downloads')\n",
    "        return self\n",
    "                                \n",
    "class CEMSLoader():\n",
    "    def __init__(self, ts_frequency='D', years=[2019], clean_on_load=True,\n",
    "                 use_pickle=True):\n",
    "        \n",
    "        print('Initializing CEMSLoader')\n",
    "        self.ts_frequency = ts_frequency\n",
    "        self.years = years\n",
    "        self.dir_path = os.path.join('data','CEMS','csvs')\n",
    "        self.clean_on_load = clean_on_load\n",
    "        \n",
    "        \n",
    "        self.use_pickle = use_pickle\n",
    "        years_clean = [str(i) for i in years]\n",
    "        years_clean = '-'.join(years_clean) #save as seperate caches\n",
    "        self.pkl_path = os.path.join('data','CEMS','processed',f'cems_{ts_frequency}_{years_clean}.pkl')\n",
    "        \n",
    "        self.cems = None\n",
    "\n",
    "    \n",
    "    def _read_csvs(self):\n",
    "        print('....reading CEMS csvs')\n",
    "        # --- Get file paths ---\n",
    "        files = os.listdir(self.dir_path)\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        \n",
    "        year_files = []\n",
    "        for y in self.years:\n",
    "            year_files += [i for i in files if str(y) in i]\n",
    "        \n",
    "        to_concat = []\n",
    "        ten_percent = int(len(files)*0.1)\n",
    "        done = 0\n",
    "        for f in files:\n",
    "            _df = pd.read_csv(os.path.join(self.dir_path, f))\n",
    "            if self.clean_on_load:\n",
    "                _df = self._clean_cems(_df)\n",
    "\n",
    "            to_concat.append(_df)\n",
    "            done +=1\n",
    "            if done % ten_percent == 0:\n",
    "                print(f'........finished loading {done}/{len(files)} csvs')\n",
    "            \n",
    "        # --- Convert to dataframe ---\n",
    "        print('....concatenating CEMS csvs')\n",
    "        self.cems = pd.concat(to_concat, axis='rows', sort=False)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def _clean_cems(self, df):\n",
    "        \n",
    "        rename_dict = {\n",
    "            'STATE':'state',\n",
    "            'ORISPL_CODE':'plant_id_eia',\n",
    "            'UNIT_ID':'unit',\n",
    "            'OP_DATE':'date',\n",
    "            'OP_HOUR':'hour',\n",
    "            'OP_TIME':'operational_time',\n",
    "            'GLOAD (MW)':'gross_load_mw',\n",
    "            'SO2_MASS (lbs)':'so2_lbs',\n",
    "            'NOX_MASS (lbs)':'nox_lbs',\n",
    "            'CO2_MASS (tons)':'co2_tons',\n",
    "        }\n",
    "\n",
    "        # --- Rename columns ---\n",
    "        df = df.rename(rename_dict, axis='columns')\n",
    "\n",
    "        # --- Convert to datetime ---\n",
    "        if self.ts_frequency != 'D':\n",
    "            df['hour'] = [str(i)+':00:00' for i in df['hour']]\n",
    "            df['datetime_utc'] = pd.to_datetime(df['date'] + ' ' + df['hour'])\n",
    "        elif self.ts_frequency == 'D':\n",
    "            df['datetime_utc'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "         # --- Aggregate by unit ---\n",
    "        agg_dict = {\n",
    "            'gross_load_mw':'sum',\n",
    "            'so2_lbs':'sum',\n",
    "            'nox_lbs':'sum',\n",
    "            'co2_tons':'sum',\n",
    "            'operational_time':'mean',\n",
    "        }\n",
    "        df = df.groupby(['plant_id_eia','datetime_utc'], as_index=False).agg(agg_dict)\n",
    "        \n",
    "        # --- Aggregate by ts_frequency ---\n",
    "        df = df.groupby('plant_id_eia').resample(self.ts_frequency, on='datetime_utc').sum()\n",
    "        df.drop(['plant_id_eia'], axis='columns', inplace=True, errors='ignore') #duplicated by resample\n",
    "        df.reset_index(inplace=True, drop=False)\n",
    "        \n",
    "                \n",
    "        # --- fill nans with zeros---\n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        # --- drop plants with a large number of zeros ---\n",
    "        df = df.loc[df.groupby('plant_id_eia')['nox_lbs'].filter(lambda x: len(x[x > 0]) > 0).index]\n",
    "        df = df.loc[df.groupby('plant_id_eia')['so2_lbs'].filter(lambda x: len(x[x > 0]) > 0).index]\n",
    "        df = df.loc[df.groupby('plant_id_eia')['co2_tons'].filter(lambda x: len(x[x > 0]) > 0).index]\n",
    "        \n",
    "        # --- Drop unnecessary columns ---\n",
    "        keep = ['datetime_utc','plant_id_eia',\n",
    "                'gross_load_mw','so2_lbs','nox_lbs','co2_tons','operational_time']\n",
    "        df = df[keep]\n",
    "\n",
    "        # --- convert co2 from tons to lbs ---\n",
    "        df['co2_lbs'] = df['co2_tons'] / 2000\n",
    "        df = df.drop(['co2_tons'], axis='columns')\n",
    "        \n",
    "        # --- reduce size ---\n",
    "        df = helper.memory_downcaster(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def _post_load_clean(self):\n",
    "        \n",
    "        print(f'........postprocessing CEMS, len: {len(self.cems)}')\n",
    "        \n",
    "        # --- drop plants without a full year of data ---\n",
    "        plant_id_eias_keep = list(set(self.cems.groupby('plant_id_eia', as_index=False)['plant_id_eia'].filter(lambda x: x.count() == 365)))\n",
    "        self.cems = self.cems.loc[self.cems['plant_id_eia'].isin(plant_id_eias_keep)]\n",
    "        print(f'........droping generators without a full year of data, len: {len(self.cems)}')\n",
    "        \n",
    "        # --- reset index ---\n",
    "        self.cems.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fetch(self):\n",
    "        \n",
    "        # --- Try to load aggregated pickle ---\n",
    "        if self.use_pickle:\n",
    "            if os.path.exists(self.pkl_path):\n",
    "                print('....reading CEMS from pickle')\n",
    "                self.cems = pd.read_pickle(self.pkl_path)\n",
    "        \n",
    "        # --- Calculate aggregate df from csvs ---\n",
    "        if not isinstance(self.cems, pd.DataFrame):\n",
    "            self._read_csvs()\n",
    "            self._post_load_clean()\n",
    "            \n",
    "            # --- Save pickle ---\n",
    "            if self.use_pickle:\n",
    "                print('....saving CEMS to pickle')\n",
    "                self.cems.to_pickle(self.pkl_path)\n",
    "                \n",
    "        return self\n",
    "        \n",
    "# --- scrape EPA CEMS data if not present in 'data/CEMS/csvs' (as zip files) ---\n",
    "scraper = EPACEMSScraper()\n",
    "scraper.fetch()\n",
    "\n",
    "# --- load CEMS data from pickle, or construct dataframe from csvs ---\n",
    "CEMS = CEMSLoader()\n",
    "CEMS.fetch()\n",
    "cems = CEMS.cems\n",
    "cems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~ LOAD WRI GPPD DATA ~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "class GPPDLoader():\n",
    "    \n",
    "    def __init__(self, ts_frequency='D', match_distance_thresh=0.01,\n",
    "                 round_coords_at=3, countries=['United States of America']):\n",
    "        self.pdir = os.path.join(os.getcwd())#, os.pardir)\n",
    "        self.ts_frequency = ts_frequency\n",
    "        \n",
    "        self.match_distance_thresh = match_distance_thresh\n",
    "        self.round_coords_at = round_coords_at #.01 degrees = 1 km\n",
    "        self.countries = countries\n",
    "\n",
    "        \n",
    "    def _load_csv(self):\n",
    "        self.gppd = pd.read_csv(os.path.join(self.pdir, 'data','wri','global_power_plant_database.csv'))\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _make_geopandas(self):\n",
    "        self.gppd = gpd.GeoDataFrame(\n",
    "            self.gppd, geometry=gpd.points_from_xy(self.gppd['longitude'], self.gppd['latitude']))\n",
    "        self.gppd.crs = \"EPSG:4326\"\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _clean_gppd(self):\n",
    "        \n",
    "        keep = [\n",
    "            'country_long',\n",
    "            'name', \n",
    "            'wri_capacity_mw',\n",
    "            'latitude',\n",
    "            'longitude',\n",
    "            'primary_fuel', \n",
    "            'commissioning_year',\n",
    "            'generation_gwh_2013',\n",
    "            'generation_gwh_2014',\n",
    "            'generation_gwh_2015',\n",
    "            'generation_gwh_2016',\n",
    "            'generation_gwh_2017',\n",
    "            'estimated_generation_gwh',\n",
    "        ]\n",
    "\n",
    "        # --- Round lat lon ---\n",
    "        self.gppd[['latitude','longitude']] = self.gppd[['latitude','longitude']].round(self.round_coords_at)\n",
    "        \n",
    "        # --- Filter country ---\n",
    "        print(f'........filtering gppd to include {self.countries}')\n",
    "        if 'all' not in self.countries: #include all countries\n",
    "            for country in self.countries:\n",
    "                assert country in set(self.gppd['country_long'])\n",
    "                self.gppd = self.gppd.loc[self.gppd['country_long'].isin(self.countries)]\n",
    "        \n",
    "        # --- Drop non fossil fuels ---\n",
    "        self.gppd = self.gppd.loc[self.gppd['primary_fuel'].isin(['Coal','Oil','Gas','Petcoke','Cogeneration'])]\n",
    "        \n",
    "        # --- Rename columns ---\n",
    "        self.gppd.rename({'capacity_mw':'wri_capacity_mw'}, axis='columns', inplace=True)\n",
    "        \n",
    "        # --- filter columns we want ---\n",
    "        self.gppd = self.gppd[keep]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def load(self):\n",
    "        print(f'....Loading gppd from csv')\n",
    "        # --- Read csv ---\n",
    "        self._load_csv()\n",
    "        \n",
    "        # --- Clean df ---\n",
    "        self._clean_gppd()\n",
    "        \n",
    "        # --- Make Geopandas ---\n",
    "        self._make_geopandas()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "GPPD = GPPDLoader() \n",
    "GPPD.load()\n",
    "gppd = GPPD.gppd\n",
    "gppd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....Loading gppd from csv\n",
      "........filtering gppd to include ['United States of America']\n",
      "........beginning merge process between gppd and eightsixty: len 2972\n",
      "........finding nearest neighboring plants between gppd and eightsixty.\n",
      "........dropping plants where no match was found: len 2503\n",
      "........merging gppd with eightsixty: len 3327\n",
      "........dropping plants with duplicate eightsixty merge: len 3327\n",
      "....constructing dt_range\n",
      "....concating gppd at hourly resolution for D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_long</th>\n",
       "      <th>name</th>\n",
       "      <th>wri_capacity_mw</th>\n",
       "      <th>primary_fuel</th>\n",
       "      <th>commissioning_year</th>\n",
       "      <th>generation_gwh_2013</th>\n",
       "      <th>generation_gwh_2014</th>\n",
       "      <th>generation_gwh_2015</th>\n",
       "      <th>generation_gwh_2016</th>\n",
       "      <th>generation_gwh_2017</th>\n",
       "      <th>...</th>\n",
       "      <th>planned_retirement_year</th>\n",
       "      <th>plant_name_eia</th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "      <th>timezone</th>\n",
       "      <th>geometry</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>1515 S Caron Road</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Gas</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>1515 S Caron Road</td>\n",
       "      <td>Rochelle</td>\n",
       "      <td>Ogle</td>\n",
       "      <td>41.908001</td>\n",
       "      <td>-89.046997</td>\n",
       "      <td>IL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-89.04700 41.90800)</td>\n",
       "      <td>01-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>191 Peachtree Tower</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Oil</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>191 Peachtree Tower</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>33.757999</td>\n",
       "      <td>-84.387001</td>\n",
       "      <td>GA</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-84.38700 33.75800)</td>\n",
       "      <td>01-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>491 E 48th Street</td>\n",
       "      <td>161.7</td>\n",
       "      <td>Gas</td>\n",
       "      <td>1996.131107</td>\n",
       "      <td>14.308000</td>\n",
       "      <td>14.985000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.034000</td>\n",
       "      <td>66.843000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>491 E 48th Street</td>\n",
       "      <td>Holland</td>\n",
       "      <td>Allegan</td>\n",
       "      <td>42.755001</td>\n",
       "      <td>-86.084999</td>\n",
       "      <td>MI</td>\n",
       "      <td>America/Detroit</td>\n",
       "      <td>POINT (-86.08500 42.75500)</td>\n",
       "      <td>01-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>500MW CC</td>\n",
       "      <td>528.0</td>\n",
       "      <td>Gas</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>3371.908049</td>\n",
       "      <td>3307.582007</td>\n",
       "      <td>2891.433025</td>\n",
       "      <td>2722.323019</td>\n",
       "      <td>2223.712995</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>500MW CC</td>\n",
       "      <td>Astoria</td>\n",
       "      <td>Queens</td>\n",
       "      <td>40.789001</td>\n",
       "      <td>-73.906998</td>\n",
       "      <td>NY</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-73.90700 40.78900)</td>\n",
       "      <td>01-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>59th Street</td>\n",
       "      <td>17.1</td>\n",
       "      <td>Gas</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>59th Street</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.771000</td>\n",
       "      <td>-73.990997</td>\n",
       "      <td>NY</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>POINT (-73.99100 40.77100)</td>\n",
       "      <td>01-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891571</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>22.3</td>\n",
       "      <td>Gas</td>\n",
       "      <td>1972.049327</td>\n",
       "      <td>1.005480</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>-0.194000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>42.806999</td>\n",
       "      <td>-86.056000</td>\n",
       "      <td>MI</td>\n",
       "      <td>America/Detroit</td>\n",
       "      <td>POINT (-86.05600 42.80700)</td>\n",
       "      <td>01-01-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891572</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Zeeland Generating Station</td>\n",
       "      <td>968.2</td>\n",
       "      <td>Gas</td>\n",
       "      <td>2001.610205</td>\n",
       "      <td>1380.350000</td>\n",
       "      <td>1999.510000</td>\n",
       "      <td>3471.259000</td>\n",
       "      <td>4000.792000</td>\n",
       "      <td>3212.419000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Zeeland Generating Station</td>\n",
       "      <td>Zeeland</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>42.820999</td>\n",
       "      <td>-85.998001</td>\n",
       "      <td>MI</td>\n",
       "      <td>America/Detroit</td>\n",
       "      <td>POINT (-85.99800 42.82100)</td>\n",
       "      <td>01-01-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891573</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>596.7</td>\n",
       "      <td>Gas</td>\n",
       "      <td>2002.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.656000</td>\n",
       "      <td>132.434005</td>\n",
       "      <td>435.493999</td>\n",
       "      <td>462.063000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Zion Energy Center</td>\n",
       "      <td>Zion</td>\n",
       "      <td>Lake</td>\n",
       "      <td>42.478001</td>\n",
       "      <td>-87.894997</td>\n",
       "      <td>IL</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>POINT (-87.89500 42.47800)</td>\n",
       "      <td>01-01-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891574</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Zorn</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Gas</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>Zorn</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>38.279999</td>\n",
       "      <td>-85.702003</td>\n",
       "      <td>KY</td>\n",
       "      <td>America/Kentucky/Louisville</td>\n",
       "      <td>POINT (-85.70200 38.28000)</td>\n",
       "      <td>01-01-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891575</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>eBay - South Jordan</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Gas</td>\n",
       "      <td>2013.775510</td>\n",
       "      <td>12.968000</td>\n",
       "      <td>51.276000</td>\n",
       "      <td>71.505000</td>\n",
       "      <td>76.392000</td>\n",
       "      <td>76.631000</td>\n",
       "      <td>...</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>eBay - South Jordan</td>\n",
       "      <td>South Jordan</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>40.561001</td>\n",
       "      <td>-112.047997</td>\n",
       "      <td>UT</td>\n",
       "      <td>America/Denver</td>\n",
       "      <td>POINT (-112.04800 40.56100)</td>\n",
       "      <td>01-01-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891576 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country_long                        name  wri_capacity_mw  \\\n",
       "0       United States of America           1515 S Caron Road              4.2   \n",
       "1       United States of America         191 Peachtree Tower              2.4   \n",
       "2       United States of America           491 E 48th Street            161.7   \n",
       "3       United States of America                    500MW CC            528.0   \n",
       "4       United States of America                 59th Street             17.1   \n",
       "...                          ...                         ...              ...   \n",
       "891571  United States of America                     Zeeland             22.3   \n",
       "891572  United States of America  Zeeland Generating Station            968.2   \n",
       "891573  United States of America          Zion Energy Center            596.7   \n",
       "891574  United States of America                        Zorn             18.0   \n",
       "891575  United States of America         eBay - South Jordan              9.8   \n",
       "\n",
       "       primary_fuel  commissioning_year  generation_gwh_2013  \\\n",
       "0               Gas         2000.000000             0.215000   \n",
       "1               Oil         1991.000000             0.000000   \n",
       "2               Gas         1996.131107            14.308000   \n",
       "3               Gas         2006.000000          3371.908049   \n",
       "4               Gas         1969.000000             0.402000   \n",
       "...             ...                 ...                  ...   \n",
       "891571          Gas         1972.049327             1.005480   \n",
       "891572          Gas         2001.610205          1380.350000   \n",
       "891573          Gas         2002.333333             0.000000   \n",
       "891574          Gas         1969.000000             0.203000   \n",
       "891575          Gas         2013.775510            12.968000   \n",
       "\n",
       "        generation_gwh_2014  generation_gwh_2015  generation_gwh_2016  \\\n",
       "0                  0.178000             0.271000             0.306000   \n",
       "1                  0.000000             0.000000             0.000000   \n",
       "2                 14.985000             0.000000            14.034000   \n",
       "3               3307.582007          2891.433025          2722.323019   \n",
       "4                  0.293000             0.000000             0.000000   \n",
       "...                     ...                  ...                  ...   \n",
       "891571            -0.344000            -0.194000             0.050000   \n",
       "891572          1999.510000          3471.259000          4000.792000   \n",
       "891573            63.656000           132.434005           435.493999   \n",
       "891574             0.078000             1.058000             0.062000   \n",
       "891575            51.276000            71.505000            76.392000   \n",
       "\n",
       "        generation_gwh_2017  ...  planned_retirement_year  \\\n",
       "0                  0.264000  ...                   2099.0   \n",
       "1                  0.000000  ...                   2099.0   \n",
       "2                 66.843000  ...                   2099.0   \n",
       "3               2223.712995  ...                   2099.0   \n",
       "4                  0.093000  ...                   2099.0   \n",
       "...                     ...  ...                      ...   \n",
       "891571             0.363000  ...                   2099.0   \n",
       "891572          3212.419000  ...                   2099.0   \n",
       "891573           462.063000  ...                   2099.0   \n",
       "891574             0.015000  ...                   2099.0   \n",
       "891575            76.631000  ...                   2099.0   \n",
       "\n",
       "                    plant_name_eia          city     county   latitude  \\\n",
       "0                1515 S Caron Road      Rochelle       Ogle  41.908001   \n",
       "1              191 Peachtree Tower       Atlanta     Fulton  33.757999   \n",
       "2                491 E 48th Street       Holland    Allegan  42.755001   \n",
       "3                         500MW CC       Astoria     Queens  40.789001   \n",
       "4                      59th Street      New York   New York  40.771000   \n",
       "...                            ...           ...        ...        ...   \n",
       "891571                     Zeeland       Zeeland     Ottawa  42.806999   \n",
       "891572  Zeeland Generating Station       Zeeland     Ottawa  42.820999   \n",
       "891573          Zion Energy Center          Zion       Lake  42.478001   \n",
       "891574                        Zorn    Louisville  Jefferson  38.279999   \n",
       "891575         eBay - South Jordan  South Jordan  Salt Lake  40.561001   \n",
       "\n",
       "         longitude  state                     timezone  \\\n",
       "0       -89.046997     IL              America/Chicago   \n",
       "1       -84.387001     GA             America/New_York   \n",
       "2       -86.084999     MI              America/Detroit   \n",
       "3       -73.906998     NY             America/New_York   \n",
       "4       -73.990997     NY             America/New_York   \n",
       "...            ...    ...                          ...   \n",
       "891571  -86.056000     MI              America/Detroit   \n",
       "891572  -85.998001     MI              America/Detroit   \n",
       "891573  -87.894997     IL              America/Chicago   \n",
       "891574  -85.702003     KY  America/Kentucky/Louisville   \n",
       "891575 -112.047997     UT               America/Denver   \n",
       "\n",
       "                           geometry        date  \n",
       "0        POINT (-89.04700 41.90800)  01-01-2019  \n",
       "1        POINT (-84.38700 33.75800)  01-01-2019  \n",
       "2        POINT (-86.08500 42.75500)  01-01-2019  \n",
       "3        POINT (-73.90700 40.78900)  01-01-2019  \n",
       "4        POINT (-73.99100 40.77100)  01-01-2019  \n",
       "...                             ...         ...  \n",
       "891571   POINT (-86.05600 42.80700)  01-01-2020  \n",
       "891572   POINT (-85.99800 42.82100)  01-01-2020  \n",
       "891573   POINT (-87.89500 42.47800)  01-01-2020  \n",
       "891574   POINT (-85.70200 38.28000)  01-01-2020  \n",
       "891575  POINT (-112.04800 40.56100)  01-01-2020  \n",
       "\n",
       "[891576 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~ MERGE DATA TOGETHER ~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "class MergeTrainingData():\n",
    "    \"\"\"\n",
    "    Merge all possible cached data for training, including:\n",
    "        - EIA 860/923 data returned from PUDLLoader()\n",
    "        - WRI Global Powerplant Database Data returned from GPPDLoader()\n",
    "        - EPA Continuous Emission Monitoring System Target Data \n",
    "    \"\"\"\n",
    "    def __init__(eightsixty, gppd, cems):\n",
    "        self.eightsixty = eightsixty\n",
    "        self.gppd = gppd\n",
    "        self.cems = cems\n",
    "        \n",
    "        \n",
    "    def _make_db_points(self, db):\n",
    "        self.db_points = list(set(db.geometry.unary_union))\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def _nearest_point(self, gppd_point):\n",
    "        # add thresh for max distance\n",
    "        _, match = nearest_points(gppd_point, self.eightsixty_points)\n",
    "        dist = gppd_point.distance(match)\n",
    "        \n",
    "        if dist < self.match_distance_thresh:\n",
    "            matched_plant_id = self.eightsixty.loc[self.eightsixty['geometry'] == match, 'plant_id_eia'].values[0]\n",
    "            return matched_plant_id\n",
    "        \n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    \n",
    "    def _duplicate_for_dates(self, df, dt_range):\n",
    "        to_concat = []\n",
    "        for d in dt_range:\n",
    "            \n",
    "            # --- Subset report year df ---\n",
    "            y = pd.Timestamp(d).year\n",
    "            _df = df.copy()\n",
    "            \n",
    "            _df['date'] = d\n",
    "            to_concat.append(_df)\n",
    "\n",
    "        long_df = pd.concat(to_concat, axis='rows')\n",
    "        return long_df\n",
    "    \n",
    "    \n",
    "    def merge(self):\n",
    "        \n",
    "        # --- Merge cems and eightsixty on eia plant id ---\n",
    "        print(f'....beginning merge process between cems and eightsixty')\n",
    "        print(f'........pre-merge generator count in eightsixty: {len(set(self.eightsixty['plant_id_eia']))}')\n",
    "        print(f'........pre-merge generator count in cems: {len(set(self.cems['plant_id_eia']))}')\n",
    "        db = self.cems.merge(self.eightsixty, on=['plant_id_eia'], how='left')\n",
    "        print(f'........post-merge generator count: {len(set(db['plant_id_eia']))}')\n",
    "              \n",
    "        import pdb; pdb.set_trace() #ensure geodataframe\n",
    "        \n",
    "        # --- Create list of known points in db ---\n",
    "        print('....making db points list.')\n",
    "        self._make_db_points()\n",
    "        \n",
    "        # --- Find nearest db plant for plants in gppd ---\n",
    "        print('....finding nearest neighboring plants between gppd and db.')\n",
    "        self.gppd['plant_id_eia'] = self.gppd['geometry'].apply(self._nearest_point)\n",
    "        \n",
    "        # --- Drop geometry from gppd to avoid duplicate columns ---\n",
    "        self.gppd.drop(['latitude','longitude','geometry'], axis='columns', inplace=True)\n",
    "        \n",
    "        # --- Filter out plants that no match was found ---\n",
    "        print(f'........pre-drop generator count in gppd: {len(self.gppd)}')\n",
    "        self.gppd = self.gppd.dropna(subset=['plant_id_eia'])\n",
    "        print(f'........post-drop generator count in gppd: {len(self.gppd)}')\n",
    "        \n",
    "        # --- Merge on plant_id_eia ---\n",
    "        print(f'........pre-merge generator count in db: {len(set(db['plant_id_eia']))}')\n",
    "        db = db.merge(self.gppd, on='plant_id_eia', how='inner')\n",
    "        print(f'........post-merge generator count in db: {len(set(db['plant_id_eia']))}')\n",
    "        \n",
    "        # --- Filter out plants that duplicate eightsixty was found ---\n",
    "        print(f'........pre-drop generator count in db: {len(set(db['plant_id_eia']))}')\n",
    "        self.gppd = self.gppd.drop_duplicates(subset=['plant_id_eia'], keep='first')\n",
    "        print(f'........post-drop generator count in db: {len(set(db['plant_id_eia']))}')\n",
    "        \n",
    "        self.db = db\n",
    "        return self\n",
    "        \n",
    "\n",
    "MERGER = MergeTrainingData(eightsixty, gppd, cems)\n",
    "MERGER.merge()\n",
    "db = MERGER.db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-17bb134d1749>\u001b[0m in \u001b[0;36m_run_jobs\u001b[0;34m(self, jobs_df)\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0;31m# --- Submit to worker ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-17bb134d1749>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0;31m# --- Submit to worker ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;31m# Take care in creating object arrays (but iterators are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_cast_to_datetime\u001b[0;34m(value, dtype, errors)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         ):\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value, convert_dates)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;31m# we only care about object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_object_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_is_dtype_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mclasses\u001b[0;34m(*klasses)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mklasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;34m\"\"\" evaluate if the tipo is a subclass of the klasses \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-17bb134d1749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0meeloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetDailyEarthEngineData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m \u001b[0mnox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgppd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-17bb134d1749>\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{db_clean}_agg{self.infered_freq}_{buffers_clean}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-17bb134d1749>\u001b[0m in \u001b[0;36m_run_jobs\u001b[0;34m(self, jobs_df)\u001b[0m\n\u001b[1;32m    143\u001b[0m                         \u001b[0mtasks_complete\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtasks_complete\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORKERS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Earth Engine Job {} / {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_complete\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_do\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/earth/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~ LOAD EARTH ENGINE DATA ~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "class GetDailyEarthEngineData():\n",
    "    \"\"\"\n",
    "    Fetch Earth Engine data for a geography.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    df (geopandas.GeoDataFrame) - Dataframe with 'generator_id', 'geometry', and 'date' columns.\n",
    "    db (string) - From https://developers.google.com/earth-engine/datasets/catalog\n",
    "    scale (int) - Granularity of calculating average values within geography\n",
    "    buffers (list) - size in meters to return data for (i.e. 1e3 for 1km)\n",
    "    days_combine (int) - Number of days to combine when calculating aggregated sattelite data\n",
    "        agg_func is applied to the returned collection of images.\n",
    "    agg_func (string) - How to calculate the daily data when aggregating multiple\n",
    "        satelitte swaths together. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    if pandas_out (bool):\n",
    "        long DataFrame\n",
    "    else:\n",
    "        list of dicts containing variables as keys\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, db='COPERNICUS/S5P/OFFL/L3_NO2',\n",
    "                 agg_func='median',\n",
    "                 scale=10, buffers=[1e3, 5e3],\n",
    "                 id_col='plant_id_eia',\n",
    "                 geo_col='geometry',\n",
    "                 date_col='date',\n",
    "                 pandas_out=True,\n",
    "                 read_cache=True, to_cache=True):\n",
    "\n",
    "        self.db = db\n",
    "        self.agg_func = agg_func\n",
    "        self.scale = scale\n",
    "        self.buffers=buffers\n",
    "        self.pandas_out = pandas_out\n",
    "        self.read_cache = read_cache\n",
    "        self.to_cache = to_cache\n",
    "        \n",
    "        self.id_col=id_col\n",
    "        self.geo_col=geo_col\n",
    "        self.date_col=date_col\n",
    "\n",
    "        \n",
    "    def _load_image(self, date):\n",
    "        \"\"\"Load Earth Edge image.\"\"\"\n",
    "        # --- Make dates strings so google is happy ---\n",
    "        start_date = date\n",
    "        next_date = (pd.Timestamp(date) + pd.tseries.offsets.DateOffset(days=1)).strftime('%m-%d-%Y') #TODO: implement frequency keyword here \n",
    "        import pdb; pdb.set_trace()\n",
    "\n",
    "        # --- Load Image and add as layer ---\n",
    "        imagecollection = ee.ImageCollection(self.db)\n",
    "        date_agg = collection.filterDate(start_date, next_date)\n",
    "\n",
    "        if self.agg_func == 'median':\n",
    "            image = date_agg.median()\n",
    "        else:\n",
    "            raise NotImplementedError(f'please write a wrapper for {self.agg_func}!')\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "    def _load_geometry(self, geometry):\n",
    "        \"\"\"Return geometry point object.\"\"\"\n",
    "        lon = geometry.x\n",
    "        lat = geometry.y\n",
    "        geometry = ee.Geometry.Point(lon, lat)\n",
    "        return geometry\n",
    "\n",
    "    \n",
    "    def _calc_geography_mean(self, date_agg, geometry):\n",
    "        \"\"\"\n",
    "        Compute Aggregation.\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        date_agg (ee.Image) - Image object that has been filtered for a date period. \n",
    "        geometry (ee.Geometry) - Geometry object that indicates the area of interest.\n",
    "        scale (int) - Integer representing the level of the detail, higher represents lower\n",
    "            representation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict - keys are bands, values are \n",
    "        \"\"\"\n",
    "        average_dict = date_agg.reduceRegion(**{\n",
    "          'reducer': ee.Reducer.mean(),\n",
    "          'geometry':geometry,\n",
    "          'scale': self.scale,\n",
    "        })\n",
    "        return average_dict\n",
    "    \n",
    "    \n",
    "    def _worker(self, row):\n",
    "        \"\"\"Returns a dict with keys as buffer size, and values of dicts of band values.\"\"\"\n",
    "        geometry = self._load_geometry(row[self.geo_col])\n",
    "        date_agg = self._load_image(row[self.date_col])\n",
    "        \n",
    "        # --- List of results, with one per buffer in self.buffers ---\n",
    "        _results = []\n",
    "        \n",
    "        for b in self.buffers:\n",
    "            _b_result = self._calc_geography_mean(date_agg, geometry)\n",
    "            _b_result[self.id_col] = self.id_col\n",
    "            _b_result[self.geo_col] = self.geo_col\n",
    "            _b_results[self.date_col] = self.date_col\n",
    "            _b_results['buffer'] = b\n",
    "            _results.append(_b_results)\n",
    "            \n",
    "        return _results\n",
    "        \n",
    "        \n",
    "    def _chunkify(self, df, n):\n",
    "        \"\"\"Break df (df) into chunks of size (n)\"\"\"\n",
    "        for i in range(0, len(df), n):\n",
    "            yield df[i:i+n]\n",
    "    \n",
    "    \n",
    "    def _run_jobs(self, jobs_df):\n",
    "        \n",
    "        if config.MULTIPROCESSING:\n",
    "            results = []\n",
    "            with cf.ThreadPoolExecutor(max_workers=config.WORKERS) as executor:\n",
    "                jobs_complete = 0\n",
    "                to_do = len(jobs_df)\n",
    "\n",
    "                # --- Chunk jobs ---\n",
    "                chunks = self._chunkify(jobs_df, config.WORKERS)\n",
    "                for chunk in chunks:\n",
    "                    \n",
    "                    # --- Submit to worker ---\n",
    "                    futures = [executor.submit(self._worker, row) for _, row in jobs_df.iterrows()]\n",
    "                    for f in cf.as_completed(futures):\n",
    "                        results.append(f.result())\n",
    "                        tasks_complete += 1\n",
    "                        if tasks_complete % config.WORKERS == 0:\n",
    "                            log.info('Finished Earth Engine Job {} / {}'.format(jobs_complete, to_do))\n",
    "        else:\n",
    "            results = [self._worker(row) for _, row in jobs_df.iterrows()]\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def _load_cache(self):\n",
    "        \n",
    "        if os.path.exists(self.cache_path):\n",
    "            with open(self.cache_path, 'rb') as handle:\n",
    "                cache = pickle.load(handle)\n",
    "        \n",
    "        else:\n",
    "            cache = pd.DataFrame({\n",
    "                self.id_col:[np.nan],\n",
    "                self.geo_col:[np.nan],\n",
    "                self.date_col:[np.nan]\n",
    "            })\n",
    "       \n",
    "        return cache\n",
    "    \n",
    "    \n",
    "    def _dump_cache(self, results):\n",
    "        with open(self.cache_path, 'wb') as handle:\n",
    "            pickle.dump(results, handle)\n",
    "        \n",
    "        return self\n",
    "             \n",
    "        \n",
    "    def _unpack_results(self, results):\n",
    "        \n",
    "        # --- Unpack 2d list to flat ---\n",
    "        results = list(itertools.chain(*results))\n",
    "        \n",
    "        if self.pandas_out:\n",
    "            \n",
    "            # --- Read list of dicts into DataFrame ---\n",
    "            results = pd.DataFrame(results)\n",
    "            \n",
    "            # --- Make long ---\n",
    "            id_vars = [self.id_col, self.date_col, self.geo_col, 'buffer']\n",
    "            results = pd.melt(results, id_vars)\n",
    "        \n",
    "        return results   \n",
    "        \n",
    "        \n",
    "    def fetch(self, df):\n",
    "        \"\"\"Top-level function.\"\"\"\n",
    "        \n",
    "        \n",
    "        # --- Construct output path ---\n",
    "        self.infered_freq = pd.infer_freq(pd.to_datetime(pd.Series(list(set(df['date'])))).sort_values())\n",
    "        db_clean = self.db.replace('/','-')\n",
    "        buffers_clean = [str(i) for i in self.buffers]\n",
    "        buffers_clean = '-'.join(buffers_clean) #save as seperate caches\n",
    "        self.pdir = os.path.join(os.getcwd(), os.pardir)\n",
    "        self.cache_path = os.path.join(self.pdir, 'cache', f\"{db_clean}_agg{self.infered_freq}_{buffers_clean}.pkl\")\n",
    "        \n",
    "        results = self._run_jobs(df)\n",
    "        results = self.unpack_results(results)\n",
    "        \n",
    "        if self.to_cache:\n",
    "            self._dump_cache(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "eeloader = GetDailyEarthEngineData()\n",
    "nox = eeloader.fetch(gppd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "- merge plants that are close to eachother\n",
    "    - add cems? add gppd? \n",
    "\n",
    "- make earth engine output a geodataframe\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# --- test that no duplicate plant_id_eias in eightsixty ---\n",
    "Counter(eightsixty['plant_id_eia']).most_common(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
